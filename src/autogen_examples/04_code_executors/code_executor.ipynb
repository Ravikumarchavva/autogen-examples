{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d05bc545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from autogen_core import CancellationToken\n",
    "from autogen_core.code_executor import CodeBlock\n",
    "from autogen_ext.code_executors.docker import DockerCommandLineCodeExecutor\n",
    "\n",
    "work_dir = Path(\"coding\")\n",
    "work_dir.mkdir(exist_ok=True)\n",
    "\n",
    "plot_code = \"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = [1, 2, 3, 4]\n",
    "y = [10, 20, 25, 30]\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.title('Sample Plot')\n",
    "plt.savefig('sample_plot.png')\n",
    "\"\"\"\n",
    "async with DockerCommandLineCodeExecutor(image='autogen_image',work_dir=work_dir) as executor:  # type: ignore\n",
    "    result = await executor.execute_code_blocks(\n",
    "        code_blocks=[\n",
    "            CodeBlock(language=\"python\", code=plot_code),\n",
    "        ],\n",
    "        cancellation_token=CancellationToken(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce23c989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommandLineCodeResult(exit_code=0, output='', code_file='coding\\\\tmp_code_e514f31a1bb4587b3d19d2ba012ca9dcdc4384ec3cf0b55461232bf0f538575e.python')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dab8243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d12a34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "\n",
    "from autogen_core import DefaultTopicId, MessageContext, RoutedAgent, default_subscription, message_handler\n",
    "from autogen_core.code_executor import CodeBlock, CodeExecutor\n",
    "from autogen_core.models import (\n",
    "    AssistantMessage,\n",
    "    ChatCompletionClient,\n",
    "    LLMMessage,\n",
    "    SystemMessage,\n",
    "    UserMessage,\n",
    ")\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Message:\n",
    "    content: str\n",
    "\n",
    "\n",
    "@default_subscription\n",
    "class Assistant(RoutedAgent):\n",
    "    def __init__(self, model_client: ChatCompletionClient) -> None:\n",
    "        super().__init__(\"An assistant agent.\")\n",
    "        self._model_client = model_client\n",
    "        self._chat_history: List[LLMMessage] = [\n",
    "            SystemMessage(\n",
    "                content=\"\"\"Write Python script in markdown block, and it will be executed.\n",
    "Always save figures to file in the current directory. Do not use plt.show(). All code required to complete this task must be contained within a single response.\"\"\",\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_message(self, message: Message, ctx: MessageContext) -> None:\n",
    "        self._chat_history.append(UserMessage(content=message.content, source=\"user\"))\n",
    "        result = await self._model_client.create(self._chat_history)\n",
    "        print(f\"\\n{'-'*80}\\nAssistant:\\n{result.content}\")\n",
    "        self._chat_history.append(AssistantMessage(content=result.content, source=\"assistant\"))  # type: ignore\n",
    "        await self.publish_message(Message(content=result.content), DefaultTopicId())  # type: ignore\n",
    "\n",
    "\n",
    "def extract_markdown_code_blocks(markdown_text: str) -> List[CodeBlock]:\n",
    "    pattern = re.compile(r\"```(?:\\s*([\\w\\+\\-]+))?\\n([\\s\\S]*?)```\")\n",
    "    matches = pattern.findall(markdown_text)\n",
    "    code_blocks: List[CodeBlock] = []\n",
    "    for match in matches:\n",
    "        language = match[0].strip() if match[0] else \"\"\n",
    "        code_content = match[1]\n",
    "        code_blocks.append(CodeBlock(code=code_content, language=language))\n",
    "    return code_blocks\n",
    "\n",
    "\n",
    "@default_subscription\n",
    "class Executor(RoutedAgent):\n",
    "    def __init__(self, code_executor: CodeExecutor) -> None:\n",
    "        super().__init__(\"An executor agent.\")\n",
    "        self._code_executor = code_executor\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_message(self, message: Message, ctx: MessageContext) -> None:\n",
    "        code_blocks = extract_markdown_code_blocks(message.content)\n",
    "        if code_blocks:\n",
    "            result = await self._code_executor.execute_code_blocks(\n",
    "                code_blocks, cancellation_token=ctx.cancellation_token\n",
    "            )\n",
    "            print(f\"\\n{'-'*80}\\nExecutor:\\n{result.output}\")\n",
    "            await self.publish_message(Message(content=result.output), DefaultTopicId())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "520c431e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Assistant:\n",
      "```python\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import yfinance as yf\n",
      "\n",
      "# Define the stock tickers for NVIDIA and Tesla\n",
      "nvidia_ticker = 'NVDA'\n",
      "tesla_ticker = 'TSLA'\n",
      "\n",
      "# Set the start and end date\n",
      "start_date = '2024-01-01'\n",
      "end_date = pd.Timestamp.today().strftime('%Y-%m-%d')\n",
      "\n",
      "# Download the stock data using yfinance\n",
      "nvidia_data = yf.download(nvidia_ticker, start=start_date, end=end_date)\n",
      "tesla_data = yf.download(tesla_ticker, start=start_date, end=end_date)\n",
      "\n",
      "# Calculate the daily returns\n",
      "nvidia_data['Return'] = nvidia_data['Adj Close'].pct_change()\n",
      "tesla_data['Return'] = tesla_data['Adj Close'].pct_change()\n",
      "\n",
      "# Cumulative returns\n",
      "nvidia_data['Cumulative Return'] = (1 + nvidia_data['Return']).cumprod()\n",
      "tesla_data['Cumulative Return'] = (1 + tesla_data['Return']).cumprod()\n",
      "\n",
      "# Plot the cumulative returns\n",
      "plt.figure(figsize=(10, 6))\n",
      "plt.plot(nvidia_data.index, nvidia_data['Cumulative Return'], label='NVIDIA (NVDA)')\n",
      "plt.plot(tesla_data.index, tesla_data['Cumulative Return'], label='Tesla (TSLA)')\n",
      "plt.title('NVIDIA vs Tesla Cumulative Stock Returns YTD from 2024-01-01')\n",
      "plt.xlabel('Date')\n",
      "plt.ylabel('Cumulative Return')\n",
      "plt.legend()\n",
      "plt.xticks(rotation=45)\n",
      "plt.grid(True)\n",
      "plt.tight_layout()\n",
      "\n",
      "# Save the plot to a file\n",
      "plt.savefig('nvidia_vs_tesla_ytd_2024.png')\n",
      "```\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Executor:\n",
      "/workspace/tmp_code_aa89300f9ab34fbb42eb31a76f09a1df75eea0ab39db8541ecae7824570a7b61.python:14: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  nvidia_data = yf.download(nvidia_ticker, start=start_date, end=end_date)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/workspace/tmp_code_aa89300f9ab34fbb42eb31a76f09a1df75eea0ab39db8541ecae7824570a7b61.python:15: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  tesla_data = yf.download(tesla_ticker, start=start_date, end=end_date)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Traceback (most recent call last):\n",
      "  File \"/app/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 3812, in get_loc\n",
      "    return self._engine.get_loc(casted_key)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"pandas/_libs/index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas/_libs/index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7096, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "KeyError: 'Adj Close'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/tmp_code_aa89300f9ab34fbb42eb31a76f09a1df75eea0ab39db8541ecae7824570a7b61.python\", line 18, in <module>\n",
      "    nvidia_data['Return'] = nvidia_data['Adj Close'].pct_change()\n",
      "                            ~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "  File \"/app/.venv/lib/python3.12/site-packages/pandas/core/frame.py\", line 4106, in __getitem__\n",
      "    return self._getitem_multilevel(key)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/app/.venv/lib/python3.12/site-packages/pandas/core/frame.py\", line 4164, in _getitem_multilevel\n",
      "    loc = self.columns.get_loc(key)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/app/.venv/lib/python3.12/site-packages/pandas/core/indexes/multi.py\", line 3059, in get_loc\n",
      "    loc = self._get_level_indexer(key, level=0)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/app/.venv/lib/python3.12/site-packages/pandas/core/indexes/multi.py\", line 3410, in _get_level_indexer\n",
      "    idx = self._get_loc_single_level_index(level_index, key)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/app/.venv/lib/python3.12/site-packages/pandas/core/indexes/multi.py\", line 2999, in _get_loc_single_level_index\n",
      "    return level_index.get_loc(key)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/app/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 3819, in get_loc\n",
      "    raise KeyError(key) from err\n",
      "KeyError: 'Adj Close'\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Assistant:\n",
      "```python\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import yfinance as yf\n",
      "\n",
      "# Define the stock tickers for NVIDIA and Tesla\n",
      "nvidia_ticker = 'NVDA'\n",
      "tesla_ticker = 'TSLA'\n",
      "\n",
      "# Set the start and end date\n",
      "start_date = '2024-01-01'\n",
      "end_date = pd.Timestamp.today().strftime('%Y-%m-%d')\n",
      "\n",
      "# Download the stock data using yfinance with auto_adjust=True\n",
      "nvidia_data = yf.download(nvidia_ticker, start=start_date, end=end_date, auto_adjust=True)\n",
      "tesla_data = yf.download(tesla_ticker, start=start_date, end=end_date, auto_adjust=True)\n",
      "\n",
      "# Calculate the daily returns\n",
      "nvidia_data['Return'] = nvidia_data['Close'].pct_change()\n",
      "tesla_data['Return'] = tesla_data['Close'].pct_change()\n",
      "\n",
      "# Cumulative returns\n",
      "nvidia_data['Cumulative Return'] = (1 + nvidia_data['Return']).cumprod()\n",
      "tesla_data['Cumulative Return'] = (1 + tesla_data['Return']).cumprod()\n",
      "\n",
      "# Plot the cumulative returns\n",
      "plt.figure(figsize=(10, 6))\n",
      "plt.plot(nvidia_data.index, nvidia_data['Cumulative Return'], label='NVIDIA (NVDA)')\n",
      "plt.plot(tesla_data.index, tesla_data['Cumulative Return'], label='Tesla (TSLA)')\n",
      "plt.title('NVIDIA vs Tesla Cumulative Stock Returns YTD from 2024-01-01')\n",
      "plt.xlabel('Date')\n",
      "plt.ylabel('Cumulative Return')\n",
      "plt.legend()\n",
      "plt.xticks(rotation=45)\n",
      "plt.grid(True)\n",
      "plt.tight_layout()\n",
      "\n",
      "# Save the plot to a file\n",
      "plt.savefig('nvidia_vs_tesla_ytd_2024.png')\n",
      "```\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Executor:\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Assistant:\n",
      "The code executed successfully, and the plot comparing NVIDIA vs Tesla cumulative stock returns YTD from 2024-01-01 has been saved as `nvidia_vs_tesla_ytd_2024.png` in the current directory.\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "\n",
    "from autogen_core import SingleThreadedAgentRuntime\n",
    "from autogen_ext.code_executors.docker import DockerCommandLineCodeExecutor\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from pathlib import Path\n",
    "\n",
    "# work_dir = tempfile.mkdtemp()\n",
    "work_dir = Path(\"coding\")\n",
    "\n",
    "# Create an local embedded runtime.\n",
    "runtime = SingleThreadedAgentRuntime()\n",
    "\n",
    "async with DockerCommandLineCodeExecutor(work_dir=work_dir, image='autogen_image') as executor:  # type: ignore[syntax]\n",
    "    # Register the assistant and executor agents by providing\n",
    "    # their agent types, the factory functions for creating instance and subscriptions.\n",
    "    model_client = OpenAIChatCompletionClient(\n",
    "        model=\"gpt-4o\",\n",
    "        # api_key=\"YOUR_API_KEY\"\n",
    "    )\n",
    "    await Assistant.register(\n",
    "        runtime,\n",
    "        \"assistant\",\n",
    "        lambda: Assistant(model_client=model_client),\n",
    "    )\n",
    "    await Executor.register(runtime, \"executor\", lambda: Executor(executor))\n",
    "\n",
    "    # Start the runtime and publish a message to the assistant.\n",
    "    runtime.start()\n",
    "    await runtime.publish_message(\n",
    "        Message(\"Create a plot of NVIDA vs TSLA stock returns YTD from 2024-01-01.\"), DefaultTopicId()\n",
    "    )\n",
    "\n",
    "    # Wait for the runtime to stop when idle.\n",
    "    await runtime.stop_when_idle()\n",
    "    # Close the connection to the model client.\n",
    "    await model_client.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e565fbf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chavv\\AppData\\Local\\Temp\\ipykernel_12940\\416134394.py:25: UserWarning: The current event loop policy is not WindowsProactorEventLoopPolicy. This may cause issues with subprocesses. Try setting the event loop policy to WindowsProactorEventLoopPolicy. For example: `asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())`. See https://docs.python.org/3/library/asyncio-eventloop.html#asyncio.ProactorEventLoop.\n",
      "  executor = LocalCommandLineCodeExecutor(work_dir=temp_dir, functions=[load_data])\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     36\u001b[39m         \u001b[38;5;28mprint\u001b[39m(result.output)  \u001b[38;5;66;03m# Output: John\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# Run the async example\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m run_example()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 32\u001b[39m, in \u001b[36mrun_example\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     25\u001b[39m executor = LocalCommandLineCodeExecutor(work_dir=temp_dir, functions=[load_data])\n\u001b[32m     26\u001b[39m code = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[33mfrom \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexecutor.functions_module\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m import load_data\u001b[39m\n\u001b[32m     27\u001b[39m \n\u001b[32m     28\u001b[39m \u001b[33m# Use the imported function\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[33mdata = load_data()\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[33mprint(data[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m\u001b[33m][0])\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m executor.execute_code_blocks(\n\u001b[32m     33\u001b[39m     code_blocks=[CodeBlock(language=\u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m, code=code)],\n\u001b[32m     34\u001b[39m     cancellation_token=CancellationToken(),\n\u001b[32m     35\u001b[39m )\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(result.output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\github\\autogen-examples\\.venv\\Lib\\site-packages\\autogen_ext\\code_executors\\local\\__init__.py:328\u001b[39m, in \u001b[36mLocalCommandLineCodeExecutor.execute_code_blocks\u001b[39m\u001b[34m(self, code_blocks, cancellation_token)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"(Experimental) Execute the code blocks and return the result.\u001b[39;00m\n\u001b[32m    319\u001b[39m \n\u001b[32m    320\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    324\u001b[39m \u001b[33;03mReturns:\u001b[39;00m\n\u001b[32m    325\u001b[39m \u001b[33;03m    CommandLineCodeResult: The result of the code execution.\"\"\"\u001b[39;00m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._setup_functions_complete:\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._setup_functions(cancellation_token)\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._execute_code_dont_check_setup(code_blocks, cancellation_token)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\github\\autogen-examples\\.venv\\Lib\\site-packages\\autogen_ext\\code_executors\\local\\__init__.py:295\u001b[39m, in \u001b[36mLocalCommandLineCodeExecutor._setup_functions\u001b[39m\u001b[34m(self, cancellation_token)\u001b[39m\n\u001b[32m    293\u001b[39m cancellation_token.link_future(task)\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m     proc = \u001b[38;5;28;01mawait\u001b[39;00m task\n\u001b[32m    296\u001b[39m     stdout, stderr = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.wait_for(proc.communicate(), \u001b[38;5;28mself\u001b[39m._timeout)\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m asyncio.TimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.11.12-windows-x86_64-none\\Lib\\asyncio\\subprocess.py:223\u001b[39m, in \u001b[36mcreate_subprocess_exec\u001b[39m\u001b[34m(program, stdin, stdout, stderr, limit, *args, **kwds)\u001b[39m\n\u001b[32m    220\u001b[39m loop = events.get_running_loop()\n\u001b[32m    221\u001b[39m protocol_factory = \u001b[38;5;28;01mlambda\u001b[39;00m: SubprocessStreamProtocol(limit=limit,\n\u001b[32m    222\u001b[39m                                                     loop=loop)\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m transport, protocol = \u001b[38;5;28;01mawait\u001b[39;00m loop.subprocess_exec(\n\u001b[32m    224\u001b[39m     protocol_factory,\n\u001b[32m    225\u001b[39m     program, *args,\n\u001b[32m    226\u001b[39m     stdin=stdin, stdout=stdout,\n\u001b[32m    227\u001b[39m     stderr=stderr, **kwds)\n\u001b[32m    228\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Process(transport, protocol, loop)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.11.12-windows-x86_64-none\\Lib\\asyncio\\base_events.py:1708\u001b[39m, in \u001b[36mBaseEventLoop.subprocess_exec\u001b[39m\u001b[34m(self, protocol_factory, program, stdin, stdout, stderr, universal_newlines, shell, bufsize, encoding, errors, text, *args, **kwargs)\u001b[39m\n\u001b[32m   1706\u001b[39m     debug_log = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mexecute program \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprogram\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m   1707\u001b[39m     \u001b[38;5;28mself\u001b[39m._log_subprocess(debug_log, stdin, stdout, stderr)\n\u001b[32m-> \u001b[39m\u001b[32m1708\u001b[39m transport = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_subprocess_transport(\n\u001b[32m   1709\u001b[39m     protocol, popen_args, \u001b[38;5;28;01mFalse\u001b[39;00m, stdin, stdout, stderr,\n\u001b[32m   1710\u001b[39m     bufsize, **kwargs)\n\u001b[32m   1711\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._debug \u001b[38;5;129;01mand\u001b[39;00m debug_log \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1712\u001b[39m     logger.info(\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m'\u001b[39m, debug_log, transport)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.11.12-windows-x86_64-none\\Lib\\asyncio\\base_events.py:503\u001b[39m, in \u001b[36mBaseEventLoop._make_subprocess_transport\u001b[39m\u001b[34m(self, protocol, args, shell, stdin, stdout, stderr, bufsize, extra, **kwargs)\u001b[39m\n\u001b[32m    499\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_make_subprocess_transport\u001b[39m(\u001b[38;5;28mself\u001b[39m, protocol, args, shell,\n\u001b[32m    500\u001b[39m                                      stdin, stdout, stderr, bufsize,\n\u001b[32m    501\u001b[39m                                      extra=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m    502\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Create subprocess transport.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m503\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "\u001b[31mNotImplementedError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import asyncio\n",
    "from autogen_core import CancellationToken\n",
    "from autogen_core.code_executor import with_requirements, CodeBlock\n",
    "from autogen_ext.code_executors.local import LocalCommandLineCodeExecutor\n",
    "import pandas\n",
    "\n",
    "@with_requirements(python_packages=[\"pandas\"], global_imports=[\"pandas\"])\n",
    "def load_data() -> pandas.DataFrame:\n",
    "    \"\"\"Load some sample data.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame with sample data\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        \"name\": [\"John\", \"Anna\", \"Peter\", \"Linda\"],\n",
    "        \"location\": [\"New York\", \"Paris\", \"Berlin\", \"London\"],\n",
    "        \"age\": [24, 13, 53, 33],\n",
    "    }\n",
    "    return pandas.DataFrame(data)\n",
    "\n",
    "async def run_example():\n",
    "    # The decorated function can be used in executed code\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        executor = LocalCommandLineCodeExecutor(work_dir=temp_dir, functions=[load_data])\n",
    "        code = f\"\"\"from {executor.functions_module} import load_data\n",
    "\n",
    "        # Use the imported function\n",
    "        data = load_data()\n",
    "        print(data['name'][0])\"\"\"\n",
    "\n",
    "        result = await executor.execute_code_blocks(\n",
    "            code_blocks=[CodeBlock(language=\"python\", code=code)],\n",
    "            cancellation_token=CancellationToken(),\n",
    "        )\n",
    "        print(result.output)  # Output: John\n",
    "\n",
    "# Run the async example\n",
    "await run_example()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59b4872",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen-examples",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
